
# Отчёт по сравнению архитектур YOLOv8n для детекции самолётов

## 1. Цель эксперимента

Цель эксперимента — сравнить качество и скорость трёх вариантов детектора на базе архитектуры YOLOv8n для задачи детекции самолётов:

- **Base** — стандартная архитектура YOLOv8n.
- **No part1** — модель с урезанной головой (удалена часть FPN/детекционных ветвей).
- **No part123** — ещё более агрессивно урезанная голова (удалены несколько частей головы, оставлены только два уровня признаков).

Сравнение проводится по стандартным метрикам детекции: **precision**, **recall**, **mAP@0.50**, **mAP@0.50:0.95**, а также по времени обучения


## 2. Данные и подготовка

### 2.1. Датасет

В качестве исходного датасета использовался **COCO 2017** (train/val), из которого была выделена подвыборка только с классом самолёта (`airplane`). Разметка была конвертирована в формат YOLO .  

Структура итоговой выборки:

```text
data/coco_airplanes/
  images/
    train/  # изображения для обучения
    val/    # изображения для валидации
  labels/
    train/  # разметка в формате YOLO
    val/
````

### 2.2. Таск и формулировка

Задача — **одноклассовая детекция** (только класс `plane`).

При этом:

* `nc = 1` (число классов) во всех модельных YAML-конфигах.
* В data-конфиге (`yolo/coco_airplanes.yaml`) заданы пути к подвыборке самолётов и имя класса `plane`.



## 3. Архитектуры моделей

Все три модели основаны на YOLOv8n (маленький вариант с минимальным числом параметров и FLOPs).

### 3.1. Base

* **Backbone** и **head** — стандартный конфиг `yolov8n.yaml` с изменённым `nc: 1`.
* Детекция ведётся с трёх уровней пирамиды признаков (P3, P4, P5).
* Используется полноценный FPN/панет-подобный neck.

### 3.2. No part1

* Из головы модели удалена часть FPN, отвечающая, в частности, за один из детекционных уровней (P3).
* Детектор использует укороченный путь с меньшим числом свёрточных блоков в голове.
* Цель изменения — уменьшить вычислительную сложность за счёт упрощения головы при минимальной потере качества.

### 3.3. No part123

* Более агрессивная редукция головы:

  * Убрано несколько последовательных фрагментов FPN/головы.
  * Оставлены только два уровня признаков (например, P4 и P5) для детекции.
* Рассматривается как «самая лёгкая» модель в серии, с ожидаемым компромиссом по качеству.



## 4. Настройки обучения

Обучение всех трёх моделей проводилось в одинаковых условиях, чтобы обеспечить корректное сравнение.

Основные параметры:

* **Фреймворк**: Ultralytics YOLOv8 (Python API).
* **Число эпох**: 50.
* **Размер входного изображения**: `imgsz = 640`.
* **Размер батча**: `batch = 32`.
* **Базовая скорость обучения**: `lr0 = 0.01` (типичное значение для SGD/AdamW в YOLO).
* **Шедулер**: `cos_lr=True` (косинусное изменение LR).
* **Оптимизатор**: `optimizer='auto'` (выбор оптимизатора и параметров доверен логике Ultralytics).

Все остальные гиперпараметры сохранены по умолчанию Ultralytics для задачи детекции.



## 5. Метрики и интерпретация

Для оценки использовались метрики, вычисляемые стандартным валидатором YOLO:

* **Precision (P)** — доля корректных предсказаний среди всех срабатываний модели (насколько мало ложных срабатываний).
* **Recall (R)** — доля найденных объектов среди всех истинных объектов (насколько мало пропусков).
* **mAP@0.50 (mAP50)** — средняя точность при IoU=0.50, «упрощённая» метрика качества детекции.
* **mAP@0.50:0.95 (mAP50-95)** — средняя по IoU ∈ [0.50, 0.95] с шагом 0.05; более строгая и комплексная метрика качества локализации.
* **val losses**:

  * `val/box_loss` — ошибка регрессии координат bbox.
  * `val/cls_loss` — ошибка классификации (для одноклассовой задачи — фактически ошибка наличия/отсутствия объекта).
  * `val/dfl_loss` — Distribution Focal Loss, связанная с качеством прогнозирования границ боксов.



## 6. Результаты экспериментов

Ниже приведены результаты на 50-й эпохе для трёх моделей (строки из `results.csv`).

### 6.1. Таблица метрик (epoch 50)

#### 6.1.1. Валидационные метрики и время

| Модель     | time (лог Ultralytics) | Precision | Recall | mAP@0.50 | mAP@0.50:0.95 | val box loss | val cls loss | val dfl loss |
| - | : | --: | --: | -: | : | --: | --: | --: |
| Base       |                  257.0 |     0.946 |  0.797 |    0.882 |         0.680 |        0.841 |        0.610 |        1.157 |
| No part1   |                  241.2 |     0.817 |  0.720 |    0.784 |         0.538 |        1.108 |        0.909 |        1.360 |
| No part123 |                  225.2 |     0.893 |  0.685 |    0.772 |         0.537 |        1.137 |        0.929 |        1.393 |

#### 6.1.2. Относительные изменения по сравнению с Base

Приблизительные относительные изменения:

* **No part1**:

  * mAP@0.50 ↓ ~11.1 % относительно Base.
  * mAP@0.50:0.95 ↓ ~20.9 %.
  * Precision ↓ ~13.6 %, Recall ↓ ~9.6 %.
  * time ↓ ~6.2 % (ускорение обучения).

* **No part123**:

  * mAP@0.50 ↓ ~12.5 %.
  * mAP@0.50:0.95 ↓ ~20.9 %.
  * Precision ↓ ~5.6 % (почти на уровне Base), но Recall ↓ ~14.0 %.
  * time ↓ ~12.4 % (ещё более быстрое обучение по сравнению с Base).



## 7. Анализ результатов

### 7.1. Модель Base

* Даёт **наилучшее качество** по всем основным метрикам:

  * mAP@0.50 ≈ 0.882
  * mAP@0.50:0.95 ≈ 0.680
  * Precision ≈ 0.946, Recall ≈ 0.797
* Валидационные лоссы (особенно `val/box_loss` и `val/dfl_loss`) минимальны среди всех трёх вариантов, что подтверждает лучшее качество локализации и формы боксов.
* Время обучения (по метрике `time`) максимальное, что ожидаемо для наиболее «тяжёлой» головы.

**Вывод:** Base — лучший выбор, если приоритет — качество детекции и нет жёстких ограничений по вычислительным ресурсам.



### 7.2. Модель No part1

* Существенное ухудшение качества:

  * mAP@0.50 падает примерно на **11 %** относительно Base.
  * Более строгая mAP@0.50:0.95 — примерно на **21 %**.
  * И precision, и recall заметно проседают.
* Все три валидационных лосса значительно выше, чем у Base, что говорит о деградации и классификации, и локализации.
* Время обучения уменьшается примерно на 6 %, что свидетельствует о некотором выигрыше в скорости.

**Интерпретация:**

Удаление части головы (No part1) снижает сложность модели и ускоряет обучение, но приводит к заметному ухудшению качества как по простым (mAP@0.50), так и по сложным (mAP@0.50:0.95) метрикам. Такая модель может быть интересна только при очень жёстких ограничениях по ресурсам, когда даже небольшое ускорение важнее падения точности.



### 7.3. Модель No part123

* Качество:

  * mAP@0.50 ещё немного ниже, чем у No part1 (≈ 0.772 против 0.784).
  * mAP@0.50:0.95 практически на том же уровне, что у No part1 (≈ 0.537).
* Интересное поведение precision/recall:

  * Precision вырастает по сравнению с No part1 и приближается к Base (0.893 против 0.946).
  * Recall, наоборот, становится ниже, чем у No part1 (0.685 против 0.720), и заметно ниже, чем у Base.
* Время обучения:

  * Наибольшее ускорение: снижение `time` примерно на **12 %** относительно Base.

**Интерпретация:**

Более агрессивное урезание головы приводит к тому, что модель:

* делает **меньше ложных срабатываний** (precision ближе к Base),
* но **пропускает больше объектов** (сильнее падает recall),
* в совокупности давая всё равно заметно меньший mAP, чем Base.

Такое поведение типично для моделей с пониженной ёмкостью (capacity): они становятся более «консервативными» и уверенными лишь на наиболее очевидных объектах.



### 7.4. Компромисс «качество / скорость»

Если обобщить:

* **Base**:

  * Лучшая mAP и лучшие лоссы.
  * Максимальное время обучения/инференса.
* **No part1**:

  * Умеренное ускорение (≈6 %).
  * Сильное падение качества (особенно по mAP@0.50:0.95).
* **No part123**:

  * Наибольшее ускорение (≈12 %).
  * Качество хуже Base, сопоставимо (но немного ниже) с No part1 по mAP, при этом более высокий precision и более низкий recall.

Для реальной эксплуатации:

* Если **качество критично** (по типу оффлайн-аналитики, важен максимум детекций) — однозначно **Base**.
* Если нужен **баланс** (немного ускорить модель при приемлемой потере качества) — No part1 или No part123, при этом нужно дополнительно смотреть на скорость инференса в целевой среде.
* Если **ресурсы сильно ограничены**, а часть пропусков допустима — No part123 выглядит наименее тяжёлой моделью с приемлемой точностью на «очевидных» примерах.


## 8. Заключение

В рамках эксперимента:

1. Были обучены три варианта YOLOv8n (Base, No part1, No part123) на подвыборке COCO с самолётами.
2. При сохранении одинаковых гиперпараметров обучения и датасета, изменение архитектуры головы позволило:

   * снизить время обучения до ~12 % (No part123),
   * но ценой падения mAP@0.50 на ~11–12 % и mAP@0.50:0.95 на ~21 % относительно базовой модели.
3. Базовая модель демонстрирует наилучший баланс precision/recall и mAP и остаётся предпочтительным вариантом при отсутствии жёстких ограничений по ресурсам.

